# Execute: streamlit run langchain_chatbot_tool_streamlit.py
# Terminate: ^C and close browser
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from tools import ALL_TOOLS, TOOL_DICT  # ë„êµ¬ë“¤ì„ import
import base64
import streamlit as st
from dotenv import load_dotenv

load_dotenv()
llm = ChatOpenAI(model="gpt-4o-mini")

# ë„êµ¬ë“¤ì„ LLMì— ë°”ì¸ë”©
llm_with_tools = llm.bind_tools(ALL_TOOLS) 

def create_model_friendly_message(tool_msg):
    """ëª¨ë¸ìš©ìœ¼ë¡œ í† í°ì„ ì ˆì•½í•œ ë©”ì‹œì§€ ìƒì„±"""
    if tool_msg.name == "get_stock_chart":
        # ì°¨íŠ¸ ë°ì´í„°ëŠ” ëª¨ë¸ì— ì „ë‹¬í•˜ì§€ ì•Šê³  ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ë¡œ ëŒ€ì²´
        return ToolMessage(
            content="[ì°¨íŠ¸ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤]",  # base64 ëŒ€ì‹  ê°„ë‹¨í•œ í…ìŠ¤íŠ¸
            tool_call_id=tool_msg.tool_call_id,
            name=tool_msg.name
        )
    else:
        # ë‹¤ë¥¸ ë„êµ¬ë“¤ì€ ê·¸ëŒ€ë¡œ ì „ë‹¬ (í•„ìš”ì‹œ ì—¬ê¸°ì„œë„ ìš”ì•½ ê°€ëŠ¥)
        return tool_msg

# ì‚¬ìš©ìì˜ ë©”ì‹œì§€ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í•¨ìˆ˜: ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
def get_ai_response(messages):
    response = llm_with_tools.stream(messages)
    
    gathered = None
    for chunk in response: # ë„êµ¬ í˜¸ì¶œì´ ìˆëŠ” ê²½ìš°ëŠ” ë‚´ìš© ì—†ìŒ
        yield chunk
        
        if gathered is None:
            gathered = chunk
        else:
            gathered += chunk

    if gathered.tool_calls:
        print(gathered)
        # UIìš©: ì›ë³¸ ë©”ì‹œì§€ ì €ì¥ (í™”ë©´ í‘œì‹œìš©)
        st.session_state.ui_messages.append(gathered)
        # ëª¨ë¸ìš©: ì›ë³¸ ë©”ì‹œì§€ ì €ì¥ (API í˜¸ì¶œìš©)
        st.session_state.model_messages.append(gathered)
        
        for tool_call in gathered.tool_calls:
            selected_tool = TOOL_DICT[tool_call['name']]  # TOOL_DICT ì‚¬ìš©
            tool_msg = selected_tool.invoke(tool_call) # llmì´ ë°˜í™˜í•œ toolì— llmì´ ë§Œë“  argsë¥¼ ë„£ì–´ í•¨ìˆ˜ê°’ ë°˜í™˜ ë°›ìŒ: ToolMessage()
            print(type(tool_msg))
            print(f"Tool result length: {len(str(tool_msg.content))}")
            
            # UIìš©: ì›ë³¸ ë°ì´í„° ì €ì¥ (ì´ë¯¸ì§€ í‘œì‹œìš©)
            st.session_state.ui_messages.append(tool_msg)
            
            # ëª¨ë¸ìš©: í† í° ì ˆì•½ ë²„ì „ ì €ì¥ (API ë¹„ìš© ì ˆì•½)
            model_friendly_msg = create_model_friendly_message(tool_msg)
            st.session_state.model_messages.append(model_friendly_msg)
            
            # ì°¨íŠ¸ì¸ ê²½ìš° ì¦‰ì‹œ ë¸Œë¼ìš°ì €ì— í‘œì‹œ
            if tool_msg.name == "get_stock_chart":
                with st.chat_message("assistant"):
                    st.image(base64.b64decode(tool_msg.content), use_container_width=True)                

        # ğŸ”‘ í•µì‹¬: ëª¨ë¸ìš© ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•´ì„œ API í˜¸ì¶œ (í† í° ì ˆì•½!)
        for chunk in get_ai_response(st.session_state.model_messages): # í† í° ì ˆì•½ëœ ë©”ì‹œì§€ë¡œ API í˜¸ì¶œ
            yield chunk

st.title("ğŸ’° í† í° ìµœì í™” Langchain ì±—ë´‡")

# ì´ˆê¸° ë©”ì‹œì§€: UIìš©ê³¼ ëª¨ë¸ìš© ë¶„ë¦¬ ê´€ë¦¬
if "ui_messages" not in st.session_state:
    initial_system = SystemMessage("ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ì¹œì ˆí•˜ê²Œ ìµœì„ ì„ ë‹¤í•´ì„œ ë•ëŠ” ì£¼ì‹ ë¶„ì„ ì¸ê³µì§€ëŠ¥ ì¡°ë ¥ìì´ë‹¤.")
    initial_ai = AIMessage("ì•ˆë…•í•˜ì„¸ìš”! ì£¼ì‹ ë¶„ì„ì„ ë„ì™€ë“œë¦´ê²Œìš”. ì–´ë–¤ ì¢…ëª©ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?")
    
    # UIìš©: í™”ë©´ í‘œì‹œë¥¼ ìœ„í•œ ë©”ì‹œì§€ (ëª¨ë“  ë°ì´í„° í¬í•¨)
    st.session_state["ui_messages"] = [initial_system, initial_ai]
    
    # ëª¨ë¸ìš©: API í˜¸ì¶œì„ ìœ„í•œ ë©”ì‹œì§€ (í† í° ì ˆì•½)
    st.session_state["model_messages"] = [initial_system, initial_ai]

# ğŸ¨ UI: í™”ë©´ì— ë©”ì‹œì§€ í‘œì‹œ (ui_messages ì‚¬ìš©)
for msg in st.session_state.ui_messages:
    if msg.content:
        if isinstance(msg, HumanMessage):
            st.chat_message("user").write(msg.content)
        elif isinstance(msg, AIMessage):
            st.chat_message("assistant").write(msg.content)
        elif isinstance(msg, ToolMessage):  
            if msg.name == "get_stock_chart":
                # UIìš© ë©”ì‹œì§€ì—ëŠ” ì›ë³¸ base64 ë°ì´í„°ê°€ ìˆìŒ
                with st.chat_message("assistant"):
                    st.image(base64.b64decode(msg.content), use_container_width=True)               

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì˜ˆ: 'AAPL ì°¨íŠ¸ ë³´ì—¬ì¤˜' ë˜ëŠ” 'í˜„ì¬ ì‹œê°„ ì•Œë ¤ì¤˜'"):
    st.chat_message("user").write(prompt) # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ëŠ” UIìš©ê³¼ ëª¨ë¸ìš© ë‘˜ ë‹¤ì— ì¶”ê°€ (í…ìŠ¤íŠ¸ë¼ì„œ í† í° ë¶€ë‹´ ì ìŒ)
    user_msg = HumanMessage(prompt)
    st.session_state.ui_messages.append(user_msg)
    st.session_state.model_messages.append(user_msg)
    
    # ğŸ¤– ëª¨ë¸ í˜¸ì¶œ: í† í° ì ˆì•½ëœ model_messages ì‚¬ìš©
    response = get_ai_response(st.session_state.model_messages) 
    
    # AI ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ í‘œì‹œ
    ai_msg = st.chat_message("assistant").write_stream(response)
    
    # AI ì‘ë‹µë„ UIìš©ê³¼ ëª¨ë¸ìš© ë‘˜ ë‹¤ì— ì €ì¥
    ai_message = AIMessage(ai_msg)
    st.session_state.ui_messages.append(ai_message)
    st.session_state.model_messages.append(ai_message)

# ğŸ“Š ì‚¬ì´ë“œë°”: í† í° ì ˆì•½ íš¨ê³¼ í‘œì‹œ
with st.sidebar:
    st.subheader("ğŸ’° í† í° ì ˆì•½ í˜„í™©")
    
    # ë©”ì‹œì§€ ê°œìˆ˜ ë¹„êµ
    ui_count = len(st.session_state.get("ui_messages", []))
    model_count = len(st.session_state.get("model_messages", []))
    st.metric("UI ë©”ì‹œì§€", ui_count)
    st.metric("ëª¨ë¸ ë©”ì‹œì§€", model_count)
    
    # ëŒ€ëµì ì¸ í† í° ì‚¬ìš©ëŸ‰ ì¶”ì •
    ui_chars = sum(len(str(msg.content or "")) for msg in st.session_state.get("ui_messages", []))
    model_chars = sum(len(str(msg.content or "")) for msg in st.session_state.get("model_messages", []))
    
    st.metric("UI ì´ ë¬¸ììˆ˜", f"{ui_chars:,}")
    st.metric("ëª¨ë¸ ì´ ë¬¸ììˆ˜", f"{model_chars:,}")
    
    if ui_chars > 0:
        savings = ((ui_chars - model_chars) / ui_chars) * 100
        st.metric("í† í° ì ˆì•½ë¥ ", f"{savings:.1f}%")
    
    st.markdown("---")
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
        initial_system = SystemMessage("ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ì¹œì ˆí•˜ê²Œ ìµœì„ ì„ ë‹¤í•´ì„œ ë•ëŠ” ì£¼ì‹ ë¶„ì„ ì¸ê³µì§€ëŠ¥ ì¡°ë ¥ìì´ë‹¤.")
        initial_ai = AIMessage("ì•ˆë…•í•˜ì„¸ìš”! ì£¼ì‹ ë¶„ì„ì„ ë„ì™€ë“œë¦´ê²Œìš”.")
        st.session_state["ui_messages"] = [initial_system, initial_ai]
        st.session_state["model_messages"] = [initial_system, initial_ai]
        st.rerun()
    
    st.markdown("**ğŸ¯ ìµœì í™” í¬ì¸íŠ¸:**")
    st.markdown("- ì°¨íŠ¸ ì´ë¯¸ì§€: UIì—ë§Œ ì €ì¥")
    st.markdown("- ëª¨ë¸ìš©: í…ìŠ¤íŠ¸ ìš”ì•½ë§Œ ì „ë‹¬")  
    st.markdown("- í† í° ë¹„ìš© ëŒ€í­ ì ˆì•½!")