from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from tools import ALL_TOOLS, TOOL_DICT  # ë„êµ¬ë“¤ì„ import
import base64
import streamlit as st
from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(model="gpt-4o")

# ë„êµ¬ë“¤ì„ LLMì— ë°”ì¸ë”©
llm_with_tools = llm.bind_tools(ALL_TOOLS) 

def display_chart_if_exists(tool_name, tool_content):
    """ë„êµ¬ ê²°ê³¼ê°€ ì°¨íŠ¸ì¸ì§€ í™•ì¸í•˜ê³  í‘œì‹œí•˜ëŠ” í•¨ìˆ˜"""
    if tool_name == "get_stock_chart":
        if isinstance(tool_content, str) and (
            tool_content.startswith("CHART_IMAGE:") or 
            (len(tool_content) > 100 and not tool_content.startswith("ERROR:"))
        ):
            try:
                # CHART_IMAGE: ì ‘ë‘ì‚¬ ì œê±°
                if tool_content.startswith("CHART_IMAGE:"):
                    image_data = tool_content.replace("CHART_IMAGE:", "")
                else:
                    image_data = tool_content
                
                # base64 ë””ì½”ë”©í•˜ì—¬ ì´ë¯¸ì§€ í‘œì‹œ
                with st.chat_message("assistant"):
                    st.image(base64.b64decode(image_data), 
                           caption="ğŸ“ˆ ì£¼ê°€ ì°¨íŠ¸", 
                           use_column_width=True)
                print(f"âœ… ì°¨íŠ¸ í‘œì‹œ ì™„ë£Œ: {tool_name}")
                return True
            except Exception as e:
                print(f"âŒ ì°¨íŠ¸ í‘œì‹œ ì˜¤ë¥˜: {e}")
                with st.chat_message("assistant"):
                    st.error("ì°¨íŠ¸ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        elif tool_content.startswith("ERROR:"):
            with st.chat_message("assistant"):
                st.error(tool_content)
            return True
    return False

# ì‚¬ìš©ìì˜ ë©”ì‹œì§€ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í•¨ìˆ˜: ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
def get_ai_response(messages):
    response = llm_with_tools.stream(messages)
    
    gathered = None
    print('===== 1ì°¨ yield ì‹œì‘ =====')
    for chunk in response: # ë„êµ¬ í˜¸ì¶œì´ ìˆëŠ” ê²½ìš°ëŠ” ë‚´ìš© ì—†ìŒ
        yield chunk
        
        if gathered is None:
            gathered = chunk
        else:
            gathered += chunk

    if gathered.tool_calls:
        print(f'===== ë„êµ¬ í˜¸ì¶œ ê°ì§€: {len(gathered.tool_calls)}ê°œ =====')
        st.session_state.messages.append(gathered)
        
        for tool_call in gathered.tool_calls:
            tool_name = tool_call['name']
            selected_tool = TOOL_DICT[tool_name]  # TOOL_DICT ì‚¬ìš©
            tool_msg = selected_tool.invoke(tool_call) 
            
            print(f"ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ íƒ€ì…: {type(tool_msg)}")
            print(f"ë„êµ¬ ì´ë¦„: {tool_name}")
            print(f"ê²°ê³¼ ê¸¸ì´: {len(str(tool_msg.content)) if tool_msg.content else 0}")
            
            # ì°¨íŠ¸ì¸ì§€ í™•ì¸í•˜ê³  ì¦‰ì‹œ í‘œì‹œ
            chart_displayed = display_chart_if_exists(tool_name, tool_msg.content)
            
            st.session_state.messages.append(tool_msg)

        print('===== 2ì°¨ yield ì‹œì‘ =====')
        for chunk in get_ai_response(st.session_state.messages): # í•¨ìˆ˜ê°’(tool_msg)ë¥¼ í¬í•¨í•´ì„œ ë‹¤ì‹œ llmì— ì…ë ¥
            yield chunk
        print('===== 2ì°¨ yield ë =====')

st.title("ğŸ“ˆ Langchain ì£¼ì‹ ë¶„ì„ ì±—ë´‡")

# ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        SystemMessage("ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ì¹œì ˆí•˜ê²Œ ìµœì„ ì„ ë‹¤í•´ì„œ ë•ëŠ” ì£¼ì‹ ë¶„ì„ ì¸ê³µì§€ëŠ¥ ì¡°ë ¥ìì´ë‹¤. ì£¼ê°€ ì°¨íŠ¸ë¥¼ ê·¸ë ¤ì„œ ë³´ì—¬ì¤„ ìˆ˜ ìˆë‹¤."),  
        AIMessage("ì•ˆë…•í•˜ì„¸ìš”! ì£¼ì‹ ë¶„ì„ì„ ë„ì™€ë“œë¦´ê²Œìš”. ì–´ë–¤ ì¢…ëª©ì˜ ì°¨íŠ¸ë¥¼ ë³´ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?")
    ]

# ìŠ¤íŠ¸ë¦¼ë¦¿ í™”ë©´ì— ë©”ì‹œì§€ ì¶œë ¥
for msg in st.session_state.messages:
    if msg.content:
        if isinstance(msg, HumanMessage):
            st.chat_message("user").write(msg.content)
        elif isinstance(msg, AIMessage):
            st.chat_message("assistant").write(msg.content)
        elif isinstance(msg, ToolMessage):
            # ë„êµ¬ ë©”ì‹œì§€ ì¤‘ ì°¨íŠ¸ê°€ ìˆìœ¼ë©´ í‘œì‹œ
            if msg.name == "get_stock_chart":
                display_chart_if_exists(msg.name, msg.content)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì˜ˆ: 'AAPL 2023-01-01ë¶€í„° 2024-01-01ê¹Œì§€ ì°¨íŠ¸ ë³´ì—¬ì¤˜'"):
    st.chat_message("user").write(prompt) # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
    st.session_state.messages.append(HumanMessage(prompt)) # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥

    response = get_ai_response(st.session_state["messages"]) # ë„êµ¬ í˜¸ì¶œì´ ì—†ëŠ” ê²½ìš° / ìˆëŠ” ê²½ìš°
    
    ai_msg = st.chat_message("assistant").write_stream(response) # AI ë©”ì‹œì§€ ì¶œë ¥
    st.session_state["messages"].append(AIMessage(ai_msg)) # AI ë©”ì‹œì§€ ì €ì¥

# ì‚¬ì´ë“œë°”ì— ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
with st.sidebar:
    st.subheader("ğŸ”§ ë””ë²„ê·¸ ì •ë³´")
    st.write(f"ì´ ë©”ì‹œì§€ ìˆ˜: {len(st.session_state.messages)}")
    
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.messages = [
            SystemMessage("ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ì¹œì ˆí•˜ê²Œ ìµœì„ ì„ ë‹¤í•´ì„œ ë•ëŠ” ì£¼ì‹ ë¶„ì„ ì¸ê³µì§€ëŠ¥ ì¡°ë ¥ìì´ë‹¤. ì£¼ê°€ ì°¨íŠ¸ë¥¼ ê·¸ë ¤ì„œ ë³´ì—¬ì¤„ ìˆ˜ ìˆë‹¤."),  
            AIMessage("ì•ˆë…•í•˜ì„¸ìš”! ì£¼ì‹ ë¶„ì„ì„ ë„ì™€ë“œë¦´ê²Œìš”. ì–´ë–¤ ì¢…ëª©ì˜ ì°¨íŠ¸ë¥¼ ë³´ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?")
        ]
        st.rerun()
    
    st.markdown("---")
    st.markdown("**ğŸ’¡ ì‚¬ìš© ì˜ˆì‹œ:**")
    st.markdown("- AAPL 2023ë…„ ì°¨íŠ¸ ë³´ì—¬ì¤˜")
    st.markdown("- í…ŒìŠ¬ë¼ ìµœê·¼ 1ë…„ ì£¼ê°€ëŠ”?")
    st.markdown("- NVDA 2023-01-01ë¶€í„° 2024-01-01ê¹Œì§€")
    
    # ìµœê·¼ ë©”ì‹œì§€ë“¤ì˜ íƒ€ì… í‘œì‹œ
    st.markdown("**ğŸ“‹ ìµœê·¼ ë©”ì‹œì§€ íƒ€ì…:**")
    for i, msg in enumerate(st.session_state.messages[-3:]):
        st.text(f"{i}: {type(msg).__name__}")
        if hasattr(msg, 'name'):
            st.text(f"   ë„êµ¬ëª…: {msg.name}")